# Elasticsearch ë¡œê·¸ ì‹œìŠ¤í…œ ì„¤ì • ê°€ì´ë“œ

ëª¨ë“  ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ë¡œê·¸ê°€ Elasticsearchì— ì €ì¥ë˜ê³  ê´€ë¦¬ë©ë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨

1. [Elasticsearch ì„¤ì¹˜](#elasticsearch-ì„¤ì¹˜)
2. [ì¸ë±ìŠ¤ ì´ˆê¸°í™”](#ì¸ë±ìŠ¤-ì´ˆê¸°í™”)
3. [í™˜ê²½ ë³€ìˆ˜ ì„¤ì •](#í™˜ê²½-ë³€ìˆ˜-ì„¤ì •)
4. [API ì‚¬ìš©ë²•](#api-ì‚¬ìš©ë²•)
5. [ë°ì´í„° êµ¬ì¡°](#ë°ì´í„°-êµ¬ì¡°)

## Elasticsearch ì„¤ì¹˜

### Docker Composeë¡œ ì„¤ì¹˜ (ì¶”ì²œ)

```yaml
# docker-compose.yml
version: '3.8'

services:
  postgres:
    image: postgres:15
    # ... ê¸°ì¡´ PostgreSQL ì„¤ì • ...

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: workflow-elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.security.enabled=false  # ê°œë°œí™˜ê²½ìš©
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - es_data:/usr/share/elasticsearch/data
    networks:
      - workflow-network

  # ì„ íƒì : Kibana (ë°ì´í„° ì‹œê°í™”)
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: workflow-kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch
    networks:
      - workflow-network

volumes:
  es_data:
    driver: local

networks:
  workflow-network:
    driver: bridge
```

### Docker Compose ì‹¤í–‰

```bash
# Elasticsearch ì‹œì‘
docker-compose up -d elasticsearch

# Elasticsearch ìƒíƒœ í™•ì¸
curl http://localhost:9200

# ì‘ë‹µ ì˜ˆì‹œ:
# {
#   "name" : "...",
#   "cluster_name" : "docker-cluster",
#   "version" : { "number" : "8.11.0", ... }
# }
```

### Python íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
# Elasticsearch í´ë¼ì´ì–¸íŠ¸ ì„¤ì¹˜
pip install elasticsearch

# ë˜ëŠ” uv ì‚¬ìš©
uv add elasticsearch
```

## ì¸ë±ìŠ¤ ì´ˆê¸°í™”

### ìë™ ì´ˆê¸°í™” (ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ)

```python
# scripts/init_elasticsearch.py
import asyncio
from services.elasticsearch.es_client import ElasticsearchClient

async def init_elasticsearch():
    """Elasticsearch ì¸ë±ìŠ¤ ì´ˆê¸°í™”"""
    es_client = ElasticsearchClient(enabled=True)
    await es_client.create_index()
    print("âœ… Elasticsearch ì¸ë±ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    await es_client.close()

if __name__ == "__main__":
    asyncio.run(init_elasticsearch())
```

```bash
# ì‹¤í–‰
cd /home/pschoi/tests/workflow_scratch_2/backend
uv run python scripts/init_elasticsearch.py
```

### ìˆ˜ë™ ì¸ë±ìŠ¤ ìƒì„±

```bash
# workflow-logs ì¸ë±ìŠ¤ ìƒì„±
curl -X PUT "localhost:9200/workflow-logs" -H 'Content-Type: application/json' -d'
{
  "mappings": {
    "properties": {
      "doc_type": { "type": "keyword" },
      "execution_id": { "type": "keyword" },
      "graph_id": { "type": "integer" },
      "timestamp": { "type": "date" },
      "level": { "type": "keyword" },
      "message": { "type": "text" },
      "node_id": { "type": "keyword" },
      "node_type": { "type": "keyword" },
      "error": { "type": "text" },
      "stack_trace": { "type": "text" },
      "status": { "type": "keyword" },
      "success": { "type": "boolean" },
      "execution_time": { "type": "float" },
      "execution_order": { "type": "keyword" },
      "node_results": { "type": "object", "enabled": false },
      "errors": { "type": "text" },
      "sequence": { "type": "integer" },
      "created_at": { "type": "date" }
    }
  }
}'

# ì¸ë±ìŠ¤ í™•ì¸
curl "localhost:9200/workflow-logs/_mapping?pretty"
```

## í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
# .env íŒŒì¼
ELASTICSEARCH_ENABLED=true
ELASTICSEARCH_URL=http://localhost:9200
# ELASTICSEARCH_USER=elastic  # ì¸ì¦ ì‚¬ìš© ì‹œ
# ELASTICSEARCH_PASSWORD=changeme
```

### Elasticsearch ë¹„í™œì„±í™”

Elasticsearch ì—†ì´ë„ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ë™ì‘í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤:

```bash
# .env
ELASTICSEARCH_ENABLED=false
```

ì´ ê²½ìš° ë¡œê·¸ ì €ì¥/ì¡°íšŒëŠ” ë™ì‘í•˜ì§€ ì•Šì§€ë§Œ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.

## API ì‚¬ìš©ë²•

### 1. ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (ë¡œê·¸ ìë™ ì €ì¥)

```bash
# ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
curl -X POST http://localhost:8000/v1/workflows/1/execute \
  -H "Content-Type: application/json" \
  -d '{
    "initial_inputs": {
      "text": "Hello World"
    }
  }'

# ì‘ë‹µ
{
  "success": true,
  "execution_id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "execution_time": 2.5,
  "node_results": {...},
  "errors": [],
  "execution_order": ["1", "2"]
}
```

### 2. ë¡œê·¸ ì¡°íšŒ

#### ì „ì²´ ë¡œê·¸ ëª©ë¡

```bash
curl "http://localhost:8000/v1/workflows/logs?limit=10"
```

#### íŠ¹ì • ì›Œí¬í”Œë¡œìš°ì˜ ë¡œê·¸

```bash
curl "http://localhost:8000/v1/workflows/1/logs?limit=10"
```

#### íŠ¹ì • ì‹¤í–‰ ë¡œê·¸ ìƒì„¸ ì¡°íšŒ

```bash
# ë©”íƒ€ë°ì´í„° + ìƒì„¸ ë¡œê·¸ ë©”ì‹œì§€
curl "http://localhost:8000/v1/workflows/logs/a1b2c3d4-e5f6-7890-abcd-ef1234567890"

# ë©”íƒ€ë°ì´í„°ë§Œ
curl "http://localhost:8000/v1/workflows/logs/a1b2c3d4-e5f6-7890-abcd-ef1234567890?include_messages=false"
```

### 3. ë¡œê·¸ ê²€ìƒ‰ (ì „ë¬¸ ê²€ìƒ‰)

```bash
# "timeout"ì´ í¬í•¨ëœ ë¡œê·¸ ê²€ìƒ‰
curl "http://localhost:8000/v1/workflows/1/logs/search?query=timeout"

# ì—ëŸ¬ ë¡œê·¸ë§Œ ê²€ìƒ‰
curl "http://localhost:8000/v1/workflows/1/logs/search?level=ERROR"

# ë³µí•© ê²€ìƒ‰
curl "http://localhost:8000/v1/workflows/1/logs/search?query=ë…¸ë“œ%20ì‹¤í–‰&level=ERROR"
```

### 4. ë¡œê·¸ ì‚­ì œ

```bash
curl -X DELETE "http://localhost:8000/v1/workflows/logs/a1b2c3d4-e5f6-7890-abcd-ef1234567890"
```

## ë°ì´í„° êµ¬ì¡°

### Elasticsearch ë¬¸ì„œ íƒ€ì…

#### 1. execution_metadata (ì‹¤í–‰ ë©”íƒ€ë°ì´í„°)

```json
{
  "doc_type": "execution_metadata",
  "execution_id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "graph_id": 1,
  "start_time": "2025-11-06T12:00:00.000Z",
  "end_time": "2025-11-06T12:00:02.500Z",
  "execution_time": 2.5,
  "status": "success",
  "success": true,
  "execution_order": ["1", "2", "3"],
  "node_results": {
    "1": {"output": "..."},
    "2": {"result": "..."}
  },
  "errors": [],
  "created_at": "2025-11-06T12:00:02.500Z",
  "log_count": 15
}
```

#### 2. log_message (ê°œë³„ ë¡œê·¸ ë©”ì‹œì§€)

```json
{
  "doc_type": "log_message",
  "execution_id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "graph_id": 1,
  "timestamp": "2025-11-06T12:00:01.234Z",
  "level": "INFO",
  "message": "ë…¸ë“œ 1 ì‹¤í–‰ ì‹œì‘",
  "node_id": "1",
  "sequence": 5
}
```

#### 3. log_message (ì—ëŸ¬)

```json
{
  "doc_type": "log_message",
  "execution_id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "graph_id": 1,
  "timestamp": "2025-11-06T12:00:02.456Z",
  "level": "ERROR",
  "message": "ë…¸ë“œ 2 ì‹¤í–‰ ì‹¤íŒ¨: timeout exceeded",
  "error": "ë…¸ë“œ 2 ì‹¤í–‰ ì‹¤íŒ¨: timeout exceeded",
  "node_id": "2",
  "sequence": 12
}
```

## Kibanaë¡œ ë¡œê·¸ í™•ì¸

### Kibana ì ‘ì†

```bash
# ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†
http://localhost:5601
```

### Index Pattern ìƒì„±

1. Management â†’ Stack Management â†’ Index Patterns
2. "Create index pattern" í´ë¦­
3. Index pattern name: `workflow-logs*`
4. Time field: `timestamp` ì„ íƒ
5. Create

### ë¡œê·¸ ê²€ìƒ‰

1. Analytics â†’ Discover
2. ì‹œê°„ ë²”ìœ„ ì„ íƒ
3. ê²€ìƒ‰:
   - `level: ERROR` - ì—ëŸ¬ ë¡œê·¸ë§Œ
   - `node_id: 1` - íŠ¹ì • ë…¸ë“œ
   - `message: timeout` - ë©”ì‹œì§€ ê²€ìƒ‰

### ëŒ€ì‹œë³´ë“œ ìƒì„±

1. Analytics â†’ Dashboard
2. Create dashboard
3. ì¶”ê°€ ê°€ëŠ¥í•œ ì‹œê°í™”:
   - ì‹œê°„ëŒ€ë³„ ë¡œê·¸ ìˆ˜ (Line chart)
   - ë ˆë²¨ë³„ ë¶„í¬ (Pie chart)
   - ì›Œí¬í”Œë¡œìš°ë³„ ì‹¤í–‰ í†µê³„ (Data table)
   - ì—ëŸ¬ ë°œìƒ ì¶”ì´ (Area chart)

## ê³ ê¸‰ ê¸°ëŠ¥

### 1. ì§ì ‘ Elasticsearch ì¿¼ë¦¬

```python
import requests

# Elasticsearchì— ì§ì ‘ ì¿¼ë¦¬
response = requests.post(
    "http://localhost:9200/workflow-logs/_search",
    json={
        "query": {
            "bool": {
                "must": [
                    {"term": {"graph_id": 1}},
                    {"match": {"message": "timeout"}}
                ]
            }
        },
        "sort": [{"timestamp": "desc"}],
        "size": 10
    }
)

results = response.json()
for hit in results["hits"]["hits"]:
    print(hit["_source"])
```

### 2. ì§‘ê³„ ì¿¼ë¦¬ (í†µê³„)

```bash
# ì›Œí¬í”Œë¡œìš°ë³„ ì‹¤í–‰ í†µê³„
curl -X POST "localhost:9200/workflow-logs/_search" -H 'Content-Type: application/json' -d'
{
  "size": 0,
  "query": {
    "term": {"doc_type": "execution_metadata"}
  },
  "aggs": {
    "by_graph": {
      "terms": {"field": "graph_id"},
      "aggs": {
        "avg_time": {"avg": {"field": "execution_time"}},
        "success_rate": {
          "value_count": {"field": "success"}
        }
      }
    }
  }
}
'
```

### 3. ì¸ë±ìŠ¤ ì •ë¦¬ (ì˜¤ë˜ëœ ë¡œê·¸ ì‚­ì œ)

```bash
# 30ì¼ ì´ìƒ ì˜¤ë˜ëœ ë¡œê·¸ ì‚­ì œ
curl -X POST "localhost:9200/workflow-logs/_delete_by_query" -H 'Content-Type: application/json' -d'
{
  "query": {
    "range": {
      "created_at": {
        "lt": "now-30d"
      }
    }
  }
}
'
```

## ë¬¸ì œ í•´ê²°

### Elasticsearch ì—°ê²° ì‹¤íŒ¨

```bash
# Elasticsearch ìƒíƒœ í™•ì¸
curl http://localhost:9200/_cluster/health

# ì»¨í…Œì´ë„ˆ ë¡œê·¸ í™•ì¸
docker logs workflow-elasticsearch
```

### ì¸ë±ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨

```bash
# ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ í›„ ì¬ìƒì„±
curl -X DELETE "localhost:9200/workflow-logs"
uv run python scripts/init_elasticsearch.py
```

### ë©”ëª¨ë¦¬ ë¶€ì¡±

```yaml
# docker-compose.ymlì—ì„œ ë©”ëª¨ë¦¬ ì¦ê°€
environment:
  - "ES_JAVA_OPTS=-Xms1g -Xmx1g"  # 1GBë¡œ ì¦ê°€
```

## ì„±ëŠ¥ ìµœì í™”

### 1. ë²Œí¬ ì¸ë±ì‹±

í˜„ì¬ êµ¬í˜„ì€ ì´ë¯¸ ë²Œí¬ ì¸ë±ì‹±ì„ ì‚¬ìš©í•©ë‹ˆë‹¤ (`bulk_index_logs`).

### 2. ì¸ë±ìŠ¤ ì„¤ì • ìµœì í™”

```bash
curl -X PUT "localhost:9200/workflow-logs/_settings" -H 'Content-Type: application/json' -d'
{
  "index": {
    "refresh_interval": "30s",
    "number_of_replicas": 0
  }
}
'
```

### 3. ì¸ë±ìŠ¤ ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬

```bash
# 30ì¼ í›„ ìë™ ì‚­ì œ ì •ì±…
curl -X PUT "localhost:9200/_ilm/policy/workflow-logs-policy" -H 'Content-Type: application/json' -d'
{
  "policy": {
    "phases": {
      "delete": {
        "min_age": "30d",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}
'
```

## ê²°ë¡ 

âœ… **ì™„ì „í•œ Elasticsearch ê¸°ë°˜ ë¡œê·¸ ì‹œìŠ¤í…œ**
- PostgreSQL í…Œì´ë¸” ë¶ˆí•„ìš”
- ê°•ë ¥í•œ ì „ë¬¸ ê²€ìƒ‰
- í™•ì¥ì„± ìš°ìˆ˜
- Kibanaë¡œ ì‹œê°í™”

**ì‹œì‘í•˜ê¸°:**
```bash
# 1. Elasticsearch ì‹œì‘
docker-compose up -d elasticsearch

# 2. ì¸ë±ìŠ¤ ì´ˆê¸°í™”
uv run python scripts/init_elasticsearch.py

# 3. ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
uv run uvicorn main:app --reload
```

ì´ì œ ëª¨ë“  ë¡œê·¸ëŠ” Elasticsearchì— ì €ì¥ë˜ê³  ê´€ë¦¬ë©ë‹ˆë‹¤! ğŸš€

